{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "vM5VDCJyAWnC",
      "metadata": {
        "id": "vM5VDCJyAWnC"
      },
      "source": [
        "# Improve ChatGPT with Knowledge Graphs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "uWz0SMuX5FFp",
      "metadata": {
        "id": "uWz0SMuX5FFp"
      },
      "outputs": [],
      "source": [
        "# pip install -q openai langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c4a39cc6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %reset -f\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "66162a41",
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "829cb1c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from string import Template\n",
        "import json\n",
        "from neo4j import GraphDatabase\n",
        "import glob\n",
        "from timeit import default_timer as timer\n",
        "from dotenv import load_dotenv\n",
        "from time import sleep\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "from langchain.schema import Document\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "beb23ada",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "XpvHDkzNnFLj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpvHDkzNnFLj",
        "outputId": "3d634edc-dbba-4294-8dcc-2ea998e7928e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.getenv(\"api_version\")\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv(\"api_key_azure\")\n",
        "\n",
        "# os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_KEY\")\n",
        "# openai.api_key = os.getenv(\"api_key_azure\")\n",
        "# openai.api_version = os.getenv(\"api_version\")\n",
        "openai_deployment = \"sdgi-gpt-35-turbo-16k\" \n",
        "# print(os.getenv(\"api_key_azure\"))\n",
        "# print(\"=====\")\n",
        "# print(os.getenv(\"api_version\"))\n",
        "# completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
        "#                                           temperature=0,\n",
        "#                                           messages=[{\"role\": \"user\",\n",
        "#                                                      \"content\": question}])\n",
        "# print(completion[\"choices\"][0][\"message\"][\"content\"])\n",
        "\n",
        "# completion = openai.chat.completions.create(\n",
        "#                     model=openai_deployment,\n",
        "#                     max_tokens=15000,\n",
        "#                     temperature=0,\n",
        "#                     messages=[\n",
        "#                         {\"role\": \"user\", \"content\": question}\n",
        "#                     ]\n",
        "#                 )\n",
        "# nlp_results = completion.choices[0].message.content\n",
        "# print(nlp_results)\n",
        "\n",
        "# print(os.environ['OPENAI_API_BASE'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "88a9f2e3-c729-455a-a338-2f83776c1d4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88a9f2e3-c729-455a-a338-2f83776c1d4c",
        "outputId": "f6c9f4d8-387b-4ffc-e200-0c35ed449d8a"
      },
      "outputs": [],
      "source": [
        "# from langchain.llms import OpenAI\n",
        "from langchain.indexes import GraphIndexCreator\n",
        "from langchain.chains import GraphQAChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "# from langchain.llms import AzureChatOpenAI\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "import networkx as nx\n",
        "import concurrent.futures\n",
        "from tqdm import tqdm  # Import tqdm for the progress bar\n",
        "\n",
        "\n",
        "def custom_sentence_tokenize(text, max_words=250):\n",
        "    words = text.split()\n",
        "    sentences = []\n",
        "    current_sentence = []\n",
        "\n",
        "    for word in words:\n",
        "        current_sentence.append(word)\n",
        "        if len(current_sentence) >= max_words:\n",
        "            sentences.append(' '.join(current_sentence))\n",
        "            current_sentence = []\n",
        "\n",
        "    if current_sentence:\n",
        "        sentences.append(' '.join(current_sentence))\n",
        "\n",
        "    return sentences\n",
        "\n",
        " \n",
        "def createGML(text, filename):\n",
        "     \n",
        "    sentences = custom_sentence_tokenize(text)\n",
        "    print(f\"********* {len(sentences)}\")\n",
        "    sleep(8)\n",
        "    try:\n",
        "        for idx, sentence in enumerate(sentences):\n",
        "            # Create a graph for each sentence\n",
        "            prompt_extractor= \"You are a networked intelligence helping a human track knowledge triples about all relevant people, things, concepts, names,places, Dates and Times, Numbers, Organizations, Products and Brands, Events, Roles and Positions, Keywords and Topics, Email Addresses and URLs, References to External Entities, Emotional Tone, Quantities and Units, Codes and Identifiers, Languages, Social Media Handles, Currencies etc. and integrating them with your knowledge stored within your weights as well as that stored in a knowledge graph. Extract all of the knowledge triples from the text. A knowledge triple is a clause that contains a subject, a predicate, and an object. The subject is the entity being described, the predicate is the property of the subject that is being described, and the object is the value of the property.\\n\\nEXAMPLE\\nIt's a state in the US. It's also the number 1 producer of gold in the US.\\n\\nOutput: (Nevada, is a, state)<|>(Nevada, is in, US)<|>(Nevada, is the number 1 producer of, gold)\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nI'm going to the store.\\n\\nOutput: NONE\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nOh huh. I know Descartes likes to drive antique scooters and play the mandolin.\\nOutput: (Descartes, likes to drive, antique scooters)<|>(Descartes, plays, mandolin)\\nEND OF EXAMPLE\\n\\nEXAMPLE\\n{text}Output:\"\n",
        "            index_creator = GraphIndexCreator(llm=AzureChatOpenAI(deployment_name=openai_deployment, temperature=0))\n",
        "            graph = index_creator.from_text(sentence, prompt=PromptTemplate(input_variables=['text'], template=prompt_extractor))\n",
        "            # print(f\" filename=== {filename} and idx=== {idx} \")\n",
        "            # Write each graph to a GML file with a unique filename\n",
        "            filenamex = f\"Models/GML/{filename}_{idx + 1}.gml\"  # Unique filename based on index\n",
        "            graph.write_to_gml(filenamex)\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating GML file {e}\")    \n",
        "\n",
        "\n",
        "def process_file(file):\n",
        "    try:\n",
        "        with open(file, \"r\") as f:\n",
        "            text = f.read().rstrip()\n",
        "            filename = file.split(\"/\")[-1].replace(\".txt\", \"\")\n",
        "            createGML(text, filename)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file}: {e}\")\n",
        "\n",
        "# def process_files_concurrently(files):\n",
        "#     with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "#         executor.map(process_file, files)\n",
        "\n",
        "\n",
        "def process_files_concurrently(files):\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # Use tqdm to create a progress bar\n",
        "        with tqdm(total=len(files)) as pbar:\n",
        "            # Define a function to update the progress bar after each task completion\n",
        "            def update(*_):\n",
        "                pbar.update()\n",
        "            \n",
        "            # Submit tasks to the ThreadPoolExecutor\n",
        "            futures = [executor.submit(process_file, file) for file in files]\n",
        "            \n",
        "            # Add the update function to the completion of each future\n",
        "            for future in concurrent.futures.as_completed(futures):\n",
        "                future.add_done_callback(update)\n",
        "\n",
        "folder=\"./Data/cleaned_text_manually/\"\n",
        "files = glob.glob(f\"{folder}*\")\n",
        "\n",
        "# process_files_concurrently(files)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(f\"Running pipeline for {len(files)} files in /Data/cleaned_text_manually/ folder\")\n",
        "\n",
        "# for i, file in enumerate(files):\n",
        "#         # print(f\"Extracting entities and relationships for {file}\")\n",
        "#         try:\n",
        "#             with open(file, \"r\") as f:\n",
        "#                  text = f.read().rstrip()\n",
        "#                 #  filename = file.split(\"/\")[-1] \n",
        "#                  filename = file.split(\"/\")[-1].replace(\".txt\", \"\")  # Extracting just the filename without the path and extension\n",
        "#                  createGML(text, filename)\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error processing {file}: {e}\")\n",
        "\n",
        "\n",
        "# # # Create a dictionary to represent the knowledge graph\n",
        "# graph_data = {\n",
        "#     \"nodes\": list(set(triplet[0] for triplet in triples + [triplet[1] for triplet in triples])),\n",
        "#     \"edges\": [{\"source\": triplet[0], \"target\": triplet[1], \"label\": triplet[2]} for triplet in triples]\n",
        "# }\n",
        "\n",
        "# # Convert graph data to JSON format\n",
        "# graph_json = json.dumps(graph_data, indent=4)\n",
        "\n",
        "# # Display or use the JSON data as needed\n",
        "# print(graph_json)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "887a3e86",
      "metadata": {},
      "outputs": [],
      "source": [
        "folder=\"./Models/GML/\"\n",
        "\n",
        "#comibine them\n",
        "# Get all .gml files in the folder\n",
        "filesGml = glob.glob(f\"{folder}*.gml\")\n",
        "\n",
        "# Initialize an empty list to hold graphs\n",
        "graphs = []\n",
        "print(f\"Combine graphs {filesGml}\")\n",
        "# Read each .gml file and append the graphs to the list\n",
        "for file in filesGml:\n",
        "    print(f\"file=== {file}\")\n",
        "    G = nx.read_gml(file)\n",
        "    graphs.append(G)\n",
        "# Combine all the graphs\n",
        "combined_graph = nx.compose_all(graphs)\n",
        "# nx.write_gml(combined_graph, 'combined_graph_model_v.gml')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed06c43d",
      "metadata": {},
      "source": [
        "### Save Graph \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0388bb7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# graph.write_to_gml(\"Models/GML/AFG-CPD-2014-EN.gml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6888973",
      "metadata": {},
      "source": [
        "### Use Saved Graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "KZIs4N5S8e8S",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "KZIs4N5S8e8S",
        "outputId": "af6ba50c-e5f6-40be-adaf-07911dab948f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphQAChain chain...\u001b[0m\n",
            "Entities Extracted:\n",
            "\u001b[32;1m\u001b[1;3mNigeria\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3mNigeria is competing for investment\n",
            "Nigeria lacks critical gas infrastructure\n",
            "Nigeria continues to fall short of Domestic Gas Supply Obligations\n",
            "Nigeria is experiencing a full-blown energy crisis\n",
            "Nigeria has National Gas Policy\n",
            "Nigeria has Country Name: Nigeria\n",
            "Nigeria has Country Code: NGA\n",
            "Nigeria has Category: NGP\n",
            "Nigeria has Document Title: Nigeria National Gas Policy\n",
            "Nigeria has Exists?: Y\n",
            "Nigeria has Publication Date: 2017\n",
            "Nigeria has Start Year: 2020\n",
            "Nigeria has End Year: 2030\n",
            "Nigeria has Language: EN\n",
            "Nigeria Identify and promote domestic gas market development projects b.\n",
            "Nigeria Gain more value from international downstream LNG markets c.\n",
            "Nigeria Clarify gas terms for PSCs d.\n",
            "Nigeria Achieve gas flare-out through gas utilisation projects utilising mature flare reduction technologies e.\n",
            "Nigeria Produce a Gas Resource Management Plan f.\n",
            "Nigeria A review of gas aggregation policy and the future role of the Gas Aggregation Company of Nigeria g.\n",
            "Nigeria Continue gas exports consistent with domestic gas market development a.\n",
            "Nigeria Investigate develop\n",
            "Nigeria builds on policy goals of the Federal Government for the gas sector\n",
            "Nigeria presented in 7 Big Wins initiative\n",
            "Nigeria developed by Ministry of Petroleum Resources\n",
            "Nigeria developed by National Economic Recovery & Growth Plan\n",
            "Nigeria is gas play\n",
            "Nigeria has proven gas reserves\n",
            "Nigeria has 9th largest gas reserves in the world\n",
            "Nigeria has more gas reserves than oil\n",
            "Nigeria can be regarded as gas province\n",
            "Nigeria has little effort made to undertake exploration for gas\n",
            "Nigeria was exposed to benign international environment\n",
            "Nigeria will struggle to compete with large gas supply volumes\n",
            "Nigeria needs to work hard to survive in constrained economic environment\n",
            "Nigeria continues to fall short of domestic gas supply obligations\n",
            "Nigeria has a Country Name\n",
            "Nigeria has a Country Code\n",
            "Nigeria has a Category\n",
            "Nigeria has a Document Title\n",
            "Nigeria has a Exists?\n",
            "Nigeria has a Publication Date\n",
            "Nigeria has a Start Year\n",
            "Nigeria has a End Year\n",
            "Nigeria has a Language\n",
            "Nigeria has a Total Energy Supply\n",
            "Nigeria has a Non-renewable (TJ)\n",
            "Nigeria has a Renewable (TJ)\n",
            "Nigeria has a Total (TJ)\n",
            "Nigeria has a Renewable share (%)\n",
            "Nigeria has a Growth in TES 2014-19\n",
            "Nigeria has a Primary energy trade\n",
            "Nigeria has a Imports (TJ)\n",
            "Nigeria has a Exports (TJ)\n",
            "Nigeria has a Net trade (TJ)\n",
            "Nigeria has a Imports (% of supply)\n",
            "Nigeria has a Exports (% of production)\n",
            "Nigeria has a Energy self-sufficiency (%)\n",
            "Nigeria has a COUNTRY INDICATORS AND SDGS TOTAL ENERGY SUPPLY (TES)\n",
            "Nigeria has a Total energy supply in 2019\n",
            "Nigeria has a Renewable energy supply in 2019\n",
            "Nigeria has a 7.1.1 Access to electricity (% population)\n",
            "Nigeria has a 7.1.2 Access to clean cooking (% population)\n",
            "Nigeria has a 7.2.1 Renewable energy (% TFEC)\n",
            "Nigeria has a PM2.5 (μm/m3 )\n",
            "Nigeria has a Urban Average\n",
            "Nigeria has a Rural\n",
            "Nigeria has a WHO safe\n",
            "Nigeria has a 11.6.2 Air particulate matter (PM2.5)\n",
            "Nigeria ranks 180 out of 193 countries in the world on women’s representation in parliament\n",
            "Nigeria has only 5.8 per cent of female legislators in the House of Representatives\n",
            "Nigeria has 7.3 per cent of female legislators in the Senate\n",
            "Nigeria scored low on the gender development index\n",
            "Nigeria scored low on the gender inequality index\n",
            "Nigeria is doing better than others at providing electricity\n",
            "Nigeria has the largest economy $429 billion US dollars in 2020\n",
            "Nigeria is the most populous 211 million in 2021\n",
            "Nigeria has poverty 40 per cent or 82.9 million people in 2019\n",
            "Nigeria has unemployment 33 per cent in 2021\n",
            "Nigeria is vulnerable conflict-related risks\n",
            "Nigeria is vulnerable environmental risks\n",
            "Nigeria has sustained inclusive economic growth and development\n",
            "Nigeria exchange lessons learned\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Based on the given knowledge triplets, the most used source of energy in Nigeria is gas. Nigeria is described as a gas play and has proven gas reserves. It is also mentioned that Nigeria has more gas reserves than oil. Additionally, there are various references to Nigeria's gas sector, gas infrastructure, and gas utilization projects. Therefore, it can be inferred that gas is the most used source of energy in Nigeria."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langchain.indexes.graph import NetworkxEntityGraph\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "loaded_graph = NetworkxEntityGraph.from_gml(\"moonshot_AI_graph_model_v2.gml\")\n",
        "\n",
        "# prompt =  \"Ignore previous output. Use the following knowledge triplets  to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"\n",
        "\n",
        "prompt =  \"Use the following knowledge triplets to answer the question at the end. If you don't know the answer, look out for potential factors in the knowledge triplets else just say I don't know based on my knowledge base, don't try to make up an answer. If a term like a Continent is used e.g Africa, Asia, replace the continent with all african countries available in the knowledge triplets. E.g Nigeria, South Africa and Egypt are under Africa. In your answer, Always refer to knowledge triplets as knowledge base.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"\n",
        "prompt_entity=\"Extract all entities from the following text. As a guideline, a proper noun is generally capitalized. You should definitely extract all names,places, Dates and Times, Numbers, Organizations, Products and Brands, Events, Roles and Positions, Keywords and Topics, Email Addresses and URLs, References to External Entities, Emotional Tone, Quantities and Units, Codes and Identifiers, Languages, Social Media Handles, Currencies..\\n\\nReturn the output as a single comma-separated list, or NONE if there is nothing of note to return.\\n\\nEXAMPLE\\ni'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.\\nOutput: Langchain\\nEND OF EXAMPLE\\n\\nEXAMPLE\\ni'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff. I'm working with Sam.\\nOutput: Langchain, Sam\\nEND OF EXAMPLE\\n\\nBegin!\\n\\n{input}\\nOutput:\"\n",
        "question = f\"\"\"\n",
        "What is the most used source of energy in Nigeria?\n",
        "\n",
        "\"\"\"\n",
        "chain = GraphQAChain.from_llm(AzureChatOpenAI(temperature=0, deployment_name= openai_deployment), graph=loaded_graph, verbose=True,\n",
        "qa_prompt=PromptTemplate(input_variables=['context', 'question'], template=prompt),\n",
        "entity_prompt=PromptTemplate(input_variables=['input'], template=prompt_entity)\n",
        ")\n",
        "response = chain.run(question) \n",
        "\n",
        "\n",
        "# IPython.display.HTML(response)\n",
        "display(Markdown(response))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
