{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This notebook creates the entity json files for subgrpahs and stores them in 00_API"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import openai\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import csv\n",
    "from collections import defaultdict\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.getenv(\"api_version\")\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv(\"api_key_azure\")\n",
    "\n",
    "# OpenAI API configuration\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"api_key_azure\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_version = os.getenv(\"api_version\")\n",
    "openai_deployment = \"sdgi-gpt-35-turbo-16k\"\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"api_key_azure\"),\n",
    "    api_version=os.getenv(\"api_version\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "embedding_model = os.getenv(\"USER_QUERY_EMBEDDING_ENGINE\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Initialize the functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "def get_answer(prompt):\n",
    "    response_entities = openai.chat.completions.create(\n",
    "        model=openai_deployment,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    )\n",
    "    response = response_entities.choices[0].message.content\n",
    "    response = json.loads(response)\n",
    "    return response\n",
    "\n",
    "def find_max_scores(lst):\n",
    "    return [i for i, x in enumerate(lst) if x > 10]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# Prompt to create subelements for each entity\n",
    "\n",
    "def create_subelements(entity):\n",
    "    subelement_relations_prompt = f\"\"\"\n",
    "    [Context]\n",
    "    You belong to a team of consultants at UNDP's Sustainable Energy Hub (SEH), working on a project to create a knowledge graph for sustainable energy. Your expertise in sustainable energy and knowledge extraction is critical for this task.\n",
    "\n",
    "    [Task]\n",
    "    You will be given an entity related to sustainable energy. Your task is to identify if the given entity has any sub-elements. A sub-element can be a sub-component, part, type, category, or example of the parent entity.\n",
    "\n",
    "    1. If no sub-elements exist, return an empty JSON array for both 'sub-elements' and 'relations'.\n",
    "    2. If sub-elements exist, extract a maximum of 5 relevant sub-elements. For each sub-element, create a relationship with the parent entity.\n",
    "\n",
    "    Each relationship should have the following attributes:\n",
    "    1. 'Sub-element': The sub-component, part, type, category, or example of the entity.\n",
    "    2. 'Relation': The fixed phrase 'is a sub-element of'.\n",
    "    3. 'Parent': The given entity (subject) of the relation.\n",
    "    4. 'Description': A explanation of the relationship, including how the sub-element fits or functions as part of the parent entity.\n",
    "    5. 'Importance': A score between 1 to 4 indicating the importance of this relationship in the context of sustainable energy, with 4 being the highest score.\n",
    "\n",
    "    [Example]\n",
    "    For the entity \"UNDP accelerator labs\":\n",
    "    {{\n",
    "        \"sub-elements\": [\n",
    "            \"solutions mapping\"\n",
    "        ],\n",
    "        \"relations\": [\n",
    "            \"Sub-element\": \"solutions mapping\",\n",
    "                \"Relation\": \"is a sub-element of\",\n",
    "                \"Parent\": \"UNDP accelerator labs\",\n",
    "                \"Description\": \"Solutions mapping is a fundamental aspect of the UNDP Accelerator Labs, involving the identification, mapping, and analysis of grassroots solutions and innovations within the community. It aims to understand local contexts and leverage indigenous knowledge to address development challenges.\",\n",
    "                \"Importance\": 4\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "    [Output Format]\n",
    "    Return a JSON object with two arrays: 'sub-elements' and 'relations'. Each element in the 'relations' array should be a JSON object with the specified attributes.\n",
    "\n",
    "    Now, create a JSON object for the following entity:\n",
    "    [Input]\n",
    "    >>>>>> Entity <<<<<<\n",
    "    {entity}\n",
    "\"\"\"\n",
    "\n",
    "    relations = get_answer(subelement_relations_prompt)\n",
    "    return relations\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "with open('../03_Output/01_Auto KGs/02_Replaced Relations/knowledge_graph_2.json', \"r\") as file:\n",
    "    data = file.read()\n",
    "    kg_nodes = json.loads(data)\n",
    "    file.close()\n",
    "\n",
    "file_path = '../03_Output/00_GPT KGs/Relations_replaced.csv'\n",
    "rel_lst = pd.read_csv(file_path, delimiter=';')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Function to get nested level of relations for a parent node\n",
    "# parent_imp: importance score of parent\n",
    "def get_level_relations(parent_score, child_df):\n",
    "    scores = {}\n",
    "    arr = [parent_score] * len(child_df)                #create an empty array to store importance scores\n",
    "    scores_lst = child_df['Importance'].tolist()\n",
    "    rows = json.loads(child_df.to_json(orient=\"records\"))\n",
    "    for index, val in enumerate(scores_lst):\n",
    "        arr[index] *= val\n",
    "    scores[obj] = arr\n",
    "    indexes = find_max_scores(arr)\n",
    "    child_df = child_df.reset_index(drop=True)\n",
    "    relations_df = child_df.iloc[indexes]\n",
    "    relations_js = [rows[val] for val in indexes]\n",
    "    return [relations_js, relations_df]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def unique_subjects(input_list, n, level):\n",
    "    if len(input_list) <= n:\n",
    "        return input_list\n",
    "    subject_count = defaultdict(int)\n",
    "    unique_list = []\n",
    "    if level == 2:\n",
    "        for item in input_list:\n",
    "            subject = item['Subject']\n",
    "            if len(unique_list) < n:\n",
    "                if subject_count[subject] < 1 or (subject_count[subject] < 2 and len(unique_list) < n):\n",
    "                    unique_list.append(item)\n",
    "                    subject_count[subject] += 1\n",
    "            else:\n",
    "                break\n",
    "    if level == 3:\n",
    "        for item in input_list:\n",
    "            subject = item['Subject']\n",
    "            if len(unique_list) < n:\n",
    "                if subject_count[subject] < 1:\n",
    "                    unique_list.append(item)\n",
    "                    subject_count[subject] += 1\n",
    "            else:\n",
    "                break\n",
    "    return unique_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the below cell to generate the levels and subelements for all entities\n",
    "Tip: To adjust the number of entities to be processed change the length of kg_nodes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "output = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "for item in kg_nodes: # Setting kg_nodes[:20] will generate json files for first 20 entities\n",
    "    relations_2 = []        # set of derived level 2 relations\n",
    "    relations_3 = []\n",
    "    df2 = pd.DataFrame()\n",
    "    df3 = pd.DataFrame()\n",
    "    subgroups = []\n",
    "    new_node = {}\n",
    "    subject = item['metadata']['Entity']\n",
    "    relations = item['knowledge graph']['relations'][subject]\n",
    "    new_node['metadata'] = item['metadata']\n",
    "    new_node['knowledge graph'] = {}\n",
    "    new_node['knowledge graph'] ['entities'] = item['knowledge graph']['entities']\n",
    "\n",
    "    for index, rel in enumerate(relations):\n",
    "        obj = rel['Object']\n",
    "        level2 = rel_lst.loc[rel_lst['Subject'].apply(lambda x: x.lower() if isinstance(x, str) else x) == obj.lower()]\n",
    "        if len(level2) != 0:\n",
    "            lst2 = get_level_relations(rel['Importance'], level2)\n",
    "            relations_2.extend(lst2[0])\n",
    "\n",
    "            df2.update(lst2[1])\n",
    "            for rel2 in relations_2:\n",
    "                level3 = rel_lst.loc[rel_lst['Subject'].apply(lambda x: x.lower() if isinstance(x, str) else x) == rel2['Object'].lower()]\n",
    "                if len(level3) != 0:\n",
    "\n",
    "                    lst3 = get_level_relations(rel['Importance'], level3)\n",
    "                    relations_3.extend(lst3[0])\n",
    "                    df3.update(lst3[1])\n",
    "    # select different relations in levels\n",
    "    selected_relations_2 = unique_subjects(relations_2, 8, 2)\n",
    "    selected_relations_3 = unique_subjects(relations_3, 4, 3)\n",
    "\n",
    "    new_node['knowledge graph']['relations'] = {}\n",
    "    new_node['knowledge graph']['relations']['level 1'] = relations\n",
    "    new_node['knowledge graph']['relations'] ['level 2'] = selected_relations_2\n",
    "    new_node['knowledge graph']['relations'] ['level 3'] = selected_relations_3\n",
    "    # get subgroups for the entity\n",
    "    gpt_output = create_subelements(subject)\n",
    "    subelements = gpt_output['sub-elements']\n",
    "    print (gpt_output)\n",
    "    subelement_relations = gpt_output['relations']\n",
    "    new_node['knowledge graph']['sub-elements'] = subelements\n",
    "    new_node['knowledge graph']['subelement_relations'] = subelement_relations\n",
    "    output.append(new_node)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n"
     ]
    }
   ],
   "source": [
    "print (len(output))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "kg_json = json.dumps(output, indent = 2)\n",
    "\n",
    "with open('../03_Output/01_Auto KGs/02_Replaced Relations/Nested Relations_3.json', 'w') as file:\n",
    "    file.write(kg_json)\n",
    "    file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "for item in output:\n",
    "    name = item['metadata']['Entity']\n",
    "    ent_json = json.dumps(item, indent = 2)\n",
    "    with open('../00_API/'+ name +'.json', 'w') as file:\n",
    "        file.write(ent_json)\n",
    "        file.close()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Replacing fuzzy matched entities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "ent_path = '../03_Output/00_GPT KGs/Entities.csv'\n",
    "entities = pd.read_csv(ent_path, delimiter=';')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "rel_path = '../03_Output/00_GPT KGs/Relations.csv'\n",
    "relations = pd.read_csv(rel_path, delimiter=';')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "def extract_synonyms_dict(csv_file_path):\n",
    "    synonyms_dict = {}\n",
    "\n",
    "    with open(csv_file_path, mode='r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile, delimiter=';')\n",
    "        for row in reader:\n",
    "            entity = row['Entity']\n",
    "            synonyms = row['Synonyms']\n",
    "            if synonyms:\n",
    "                # Split the synonyms by semicolon and strip any leading/trailing whitespace\n",
    "                synonym_list = [syn.strip() for syn in synonyms.split(';')]\n",
    "                for synonym in synonym_list:\n",
    "                    synonyms_dict[synonym] = entity\n",
    "\n",
    "    return synonyms_dict\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data security': 'data equity', 'data quality': 'data equity', 'internet of things': 'internet of energy', 'net zero energy': 'internet of energy', 'geographic information system': 'geospatial information systems', 'energy planning': 'energy modeling', 'inclusive finance': 'digital inclusive finance', 'renewable energy system': 'decentralized energy systems', 'energy efficiency policy': 'energy efficiency', 'energy efficiency programs': 'energy efficiency', 'energy efficiency goals': 'energy efficiency', 'energy efficiency performance': 'energy efficiency', 'energy efficiency initiatives': 'energy efficiency', 'energy efficiency measures': 'energy efficiency', 'energy efficiency improvements': 'energy efficiency', 'energy efficiency targets': 'energy efficiency', 'carbon footprint': 'carbon pricing', 'carbon pricing mechanisms': 'carbon pricing', 'circular economy principles': 'circular economy', 'circular economy solution': 'circular economy', 'circular economy goals': 'circular economy', 'energy waste': 'energy storage', 'energy storage capacity': 'energy storage', 'energy savings': 'energy storage', 'energy data': 'energy storage', 'energy storage solutions': 'energy storage', 'energy storage policy': 'energy storage', 'energy surveys': 'energy storage', 'multi-stakeholder approach': 'multi-stakeholder partnerships', 'microgrid systems': 'micro grids', 'smart grids': 'micro grids', 'social cohesion': 'social protection', 'financial protection': 'social protection', 'energy transition': 'just energy transition', 'clean energy transition': 'just energy transition', 'energy transition funds': 'just energy transition', 'democratic energy transition': 'just energy transition', 'energy transition progress': 'just energy transition', 'sustainable energy transition': 'just energy transition', 'energy transition strategy': 'just energy transition', 'energy transition plan': 'just energy transition', 'energy transition theory': 'just energy transition', 'energy transition goals': 'just energy transition', 'clean cooking solutions': 'clean cooking', 'community-based energy solutions': 'community-led solutions', 'community-based organizations': 'community-led solutions', 'disaster resilience': 'energy resilience', 'grid resilience': 'energy resilience', 'energy resilience grants': 'energy resilience', 'marine renewable energy': 'offshore renewable energy', 'research on renewable energy': 'offshore renewable energy', 'renewable energy': 'offshore renewable energy', 'green economy': 'blue economy', 'decentralization': 'decarbonization', 'smallholder farmers': 'energy for smallholder farmers', 'energy performance': 'energy governance', 'sustainable energy governance': 'energy governance', 'energy startups': 'energy markets', 'energy access': 'energy markets', 'energy audits': 'energy markets', 'energy market': 'energy markets', 'energy market monopoly': 'energy markets', 'gender mainstreaming program': 'gender mainstreaming', 'gender mainstreaming strategy': 'gender mainstreaming', 'gender mainstreaming programs': 'gender mainstreaming', 'microfinance programs': 'micro-finance', 'rural communities': 'marginalized communities', 'electrification': 'electrification planning', 'gender disparities': 'gender disparities in energy', 'energy inequality': 'energy and health', 'energy storage incentive programs': 'energy tax incentives', 'government incentives': 'energy tax incentives', 'energy poverty': 'energy poverty indices', 'energy import policies': 'energy poverty indices', 'livelihood opportunities': 'Action Opportunities', 'public-private partnership': 'public-private partnerships', 'climate finance programs': 'climate finance mechanisms', 'climate finance': 'climate finance mechanisms', 'energy security': 'energy democracy', 'energy demand': 'energy democracy', 'renewable energy integration': 'renewable energy certificates', 'renewable energy workforce': 'renewable energy certificates', 'renewable energy startups': 'renewable energy certificates', 'renewable energy cooperatives': 'renewable energy certificates', 'energy certificates': 'renewable energy certificates', 'renewable energy portfolio': 'renewable energy certificates', 'infrastructure': 'resilient infrastructure', 'charging infrastructure': 'resilient infrastructure', 'hydrogen infrastructure': 'resilient infrastructure', 'green infrastructure': 'resilient infrastructure', 'energy policy': 'energy diplomacy', 'climate resilience': 'climate resilience funds', 'climate resilience fund': 'climate resilience funds', 'climate resilience index': 'climate resilience funds', 'resilience building': 'green buildings', 'climate adaptation': 'climate adaptation strategies', 'entrepreneurship': 'energy entrepreneurship', 'women entrepreneurs': 'energy entrepreneurship', 'carbon offsetting programs': 'carbon offset programs', 'energy data management': 'energy data analytics', 'energy market analysis': 'energy data analytics', 'data analytics': 'energy data analytics', 'energy analysts': 'energy data analytics', 'energy conservation': 'energy cooperatives', 'energy experts': 'energy cooperatives', 'energy companies': 'energy cooperatives', 'community-based climate resilience projects': 'community-based energy resilience programs', 'community-based energy planning': 'community-based energy resilience programs', 'smart contracts': 'smart energy contracts', 'smart grid technology': 'smart metering technologies', 'battery technologies': 'smart metering technologies', 'smart metering technology': 'smart metering technologies', 'data governance principles': 'data governance frameworks', 'data governance': 'data governance frameworks', 'energy infrastructure planning': 'energy infrastructure services', 'ocean energy': 'solar energy', 'wave energy': 'wind energy', 'climate change goals': 'climate change scenario analysis', 'environmental impact': 'environmental impact assessments', 'environmental impact assessment process': 'environmental impact assessments', 'environmental assessment': 'environmental impact assessments', 'climate change agreements': 'data sharing agreements', 'data sharing platforms': 'data sharing agreements', 'energy data platform': 'energy data repositories', 'technology transfer programs': 'technology transfer', 'intergenerational justice': 'intergenerational equity', 'indigenous rights': 'indigenous land rights', 'traditional knowledge': 'traditional ecological knowledge', 'cultural impact': 'cultural impact assessments', 'land stewardship': 'land stewardship agerements', 'clean energy technologies': 'traditional energy technologies', 'bioenergy technology': 'traditional energy technologies', 'energy management systems': 'energy transport systems', 'battery performance': 'battery storage', 'energy storage systems': 'hybrid energy storage systems', 'resilient energy systems': 'resilient energy storage systems', 'anaerobic digestion': 'biodigestion', 'power generation': 'cogeneration', 'renewable energy infrastructure': 'foundational energy infrastructure', 'gasification plants': 'gasification', 'battery recycling program': 'battery recycling', 'national development plans': 'multilateral development banks', 'development banks': 'multilateral development banks', 'international organizations': 'regional energy organizations', 'environmental organizations': 'regional energy organizations', 'renewable energy organization': 'regional energy organizations', 'geological survey organizations': 'regional energy organizations', 'renewable energy projects': 'renewable energy agencies', 'renewable energy generation': 'renewable energy agencies', 'renewable energy mapping': 'renewable energy agencies', 'renewable energy access': 'renewable energy agencies', 'renewable energy research': 'renewable energy agencies', 'renewable energy technologies': 'renewable energy agencies', 'renewable energy capacity': 'renewable energy agencies', 'renewable energy sources': 'renewable energy agencies', 'international renewable energy agency': 'renewable energy agencies', 'renewable energy transition': 'renewable energy agencies', 'renewable energy solutions': 'renewable energy agencies', 'renewable energy deployment': 'renewable energy agencies', 'renewable energy investments': 'renewable energy agencies', 'renewable energy market': 'renewable energy agencies', 'renewable energy companies': 'renewable energy agencies', 'renewable energy adoption': 'renewable energy agencies', 'renewable energy providers': 'renewable energy agencies', 'renewable energy standards': 'renewable energy agencies', 'renewable energy incentives': 'renewable energy agencies', 'renewable energy performance': 'renewable energy agencies', 'renewable energy developers': 'renewable energy agencies', 'renewable energy solution': 'renewable energy agencies', 'renewable energy goals': 'renewable energy agencies', 'renewable energy experts': 'renewable energy agencies', 'energy market regulations': 'energy market and trade organizations', 'energy market integration': 'energy market and trade organizations', 'energy intensive industries': 'energy ministries', 'energy generation': 'energy and modernization', 'grid modernization': 'energy and modernization', 'paris agreement': 'Paris Agreement Goals', 'energy subsidy programs': 'energy subsisides reform', 'energy subsidies': 'energy subsisides reform', 'blue carbon funds': 'blue carbon'}\n"
     ]
    }
   ],
   "source": [
    "synonyms_dict = extract_synonyms_dict(ent_path)\n",
    "print(synonyms_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def update_csv_and_create_json(csv_file_path, updated_csv_file_path, json_file_path, synonyms_dict):\n",
    "    updated_entities = []\n",
    "\n",
    "    with open(csv_file_path, mode='r', encoding='utf-8') as csvfile, \\\n",
    "         open(updated_csv_file_path, mode='w', encoding='utf-8', newline='') as updated_csvfile:\n",
    "\n",
    "        reader = csv.DictReader(csvfile, delimiter=',')\n",
    "        fieldnames = reader.fieldnames\n",
    "        writer = csv.DictWriter(updated_csvfile, fieldnames=fieldnames, delimiter=';')\n",
    "        writer.writeheader()\n",
    "\n",
    "        for row in reader:\n",
    "            entity = row['Object'].lower()\n",
    "            if entity in synonyms_dict:\n",
    "                row['Object'] = synonyms_dict[entity]\n",
    "            else:\n",
    "                row['Object'] = entity\n",
    "\n",
    "            writer.writerow(row)\n",
    "            updated_entities.append(row)\n",
    "\n",
    "    with open(json_file_path, mode='w', encoding='utf-8') as jsonfile:\n",
    "        json.dump(updated_entities, jsonfile, indent=4)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV updated and JSON file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "\n",
    "updated_csv_file_path = '../03_Output/00_GPT KGs/Relations_replaced.csv'\n",
    "json_file_path = '../03_Output/00_GPT KGs/Relations_replaced.json'\n",
    "\n",
    "update_csv_and_create_json(rel_path, updated_csv_file_path, json_file_path, synonyms_dict)\n",
    "\n",
    "print(\"CSV updated and JSON file created successfully.\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
