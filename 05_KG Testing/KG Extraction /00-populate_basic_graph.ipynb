{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's get started with Method 1...\n",
    "\n",
    "If you are running this notebook on Google Colab, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install py2neo\n",
    "!pip install wikipedia\n",
    "!pip install spacy==3.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e7158f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from scikit-learn) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from scikit-learn) (3.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/Users/davidoluyalegbenga/.pyenv/versions/3.9.6/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.2\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import urllib\n",
    "from pprint import pprint\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from py2neo import Node, Graph, Relationship, NodeMatcher\n",
    "from py2neo.bulk import merge_nodes\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wikipedia\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Doc, Span, Token\n",
    "\n",
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.0.0) was trained with spaCy v3.0.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer']\n",
      "['tok2vec', 'tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer', 'merge_noun_chunks']\n"
     ]
    }
   ],
   "source": [
    "SUBJECTS = [\"nsubj\", \"nsubjpass\", \"csubj\", \"csubjpass\", \"agent\", \"expl\"]\n",
    "VERBS = ['ROOT', 'advcl']\n",
    "OBJECTS = [\"dobj\", \"dative\", \"attr\", \"oprd\", 'pobj']\n",
    "ENTITY_LABELS = ['PERSON', 'NORP', 'GPE', 'ORG', 'FAC', 'LOC', 'PRODUCT', 'EVENT', 'WORK_OF_ART']\n",
    "\n",
    "api_key = open('../../.api_key').read()\n",
    "\n",
    "non_nc = spacy.load('en_core_web_md')\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "nlp.add_pipe('merge_noun_chunks')\n",
    "\n",
    "print(non_nc.pipe_names)\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Query Google Knowledge Graph\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def query_google(query, api_key, limit=10, indent=True, return_lists=True):\n",
    "    \n",
    "    text_ls = []\n",
    "    node_label_ls = []\n",
    "    url_ls = []\n",
    "    \n",
    "    params = {\n",
    "        'query': query,\n",
    "        'limit': limit,\n",
    "        'indent': indent,\n",
    "        'key': api_key,\n",
    "    }   \n",
    "    \n",
    "    service_url = 'https://kgsearch.googleapis.com/v1/entities:search'\n",
    "    url = service_url + '?' + urllib.parse.urlencode(params)\n",
    "    response = json.loads(urllib.request.urlopen(url).read())\n",
    "    \n",
    "    if return_lists:\n",
    "        for element in response['itemListElement']:\n",
    "\n",
    "            try:\n",
    "                node_label_ls.append(element['result']['@type'])\n",
    "            except:\n",
    "                node_label_ls.append('')\n",
    "\n",
    "            try:\n",
    "                text_ls.append(element['result']['detailedDescription']['articleBody'])\n",
    "            except:\n",
    "                text_ls.append('')\n",
    "                \n",
    "            try:\n",
    "                url_ls.append(element['result']['detailedDescription']['url'])\n",
    "            except:\n",
    "                url_ls.append('')\n",
    "                \n",
    "        return text_ls, node_label_ls, url_ls\n",
    "    \n",
    "    else:\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Helper functions for text cleaning\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    \n",
    "    regex = re.compile(r'[\\n\\r\\t]')\n",
    "    clean_text = regex.sub(\" \", text)\n",
    "    \n",
    "    return clean_text\n",
    "\n",
    "\n",
    "def remove_stop_words_and_punct(text, print_text=False):\n",
    "    \n",
    "    result_ls = []\n",
    "    rsw_doc = non_nc(text)\n",
    "    \n",
    "    for token in rsw_doc:\n",
    "        if print_text:\n",
    "            print(token, token.is_stop)\n",
    "            print('--------------')\n",
    "        if not token.is_stop and not token.is_punct:\n",
    "            result_ls.append(str(token))\n",
    "    \n",
    "    result_str = ' '.join(result_ls)\n",
    "\n",
    "    return result_str\n",
    "\n",
    "\n",
    "def create_svo_lists(doc, print_lists):\n",
    "    \n",
    "    subject_ls = []\n",
    "    verb_ls = []\n",
    "    object_ls = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.dep_ in SUBJECTS:\n",
    "            subject_ls.append((token.lower_, token.idx))\n",
    "        elif token.dep_ in VERBS:\n",
    "            verb_ls.append((token.lemma_, token.idx))\n",
    "        elif token.dep_ in OBJECTS:\n",
    "            object_ls.append((token.lower_, token.idx))\n",
    "\n",
    "    if print_lists:\n",
    "        print('SUBJECTS: ', subject_ls)\n",
    "        print('VERBS: ', verb_ls)\n",
    "        print('OBJECTS: ', object_ls)\n",
    "    \n",
    "    return subject_ls, verb_ls, object_ls\n",
    "\n",
    "\n",
    "def remove_duplicates(tup, tup_posn):\n",
    "    \n",
    "    check_val = set()\n",
    "    result = []\n",
    "    \n",
    "    for i in tup:\n",
    "        if i[tup_posn] not in check_val:\n",
    "            result.append(i)\n",
    "            check_val.add(i[tup_posn])\n",
    "            \n",
    "    return result\n",
    "\n",
    "\n",
    "def remove_dates(tup_ls):\n",
    "    \n",
    "    clean_tup_ls = []\n",
    "    for entry in tup_ls:\n",
    "        if not entry[2].isdigit():\n",
    "            clean_tup_ls.append(entry)\n",
    "    return clean_tup_ls\n",
    "\n",
    "\n",
    "def create_svo_triples(text, print_lists=False):\n",
    "    \n",
    "    clean_text = remove_special_characters(text)\n",
    "    doc = nlp(clean_text)\n",
    "    subject_ls, verb_ls, object_ls = create_svo_lists(doc, print_lists=print_lists)\n",
    "    \n",
    "    graph_tup_ls = []\n",
    "    dedup_tup_ls = []\n",
    "    clean_tup_ls = []\n",
    "    \n",
    "    for subj in subject_ls: \n",
    "        for obj in object_ls:\n",
    "            \n",
    "            dist_ls = []\n",
    "            \n",
    "            for v in verb_ls:\n",
    "                \n",
    "                # Assemble a list of distances between each object and each verb\n",
    "                dist_ls.append(abs(obj[1] - v[1]))\n",
    "                \n",
    "            # Get the index of the verb with the smallest distance to the object \n",
    "            # and return that verb\n",
    "            index_min = min(range(len(dist_ls)), key=dist_ls.__getitem__)\n",
    "            \n",
    "            # Remve stop words from subjects and object.  Note that we do this a bit\n",
    "            # later down in the process to allow for proper sentence recognition.\n",
    "\n",
    "            no_sw_subj = remove_stop_words_and_punct(subj[0])\n",
    "            no_sw_obj = remove_stop_words_and_punct(obj[0])\n",
    "            \n",
    "            # Add entries to the graph iff neither subject nor object is blank\n",
    "            if no_sw_subj and no_sw_obj:\n",
    "                tup = (no_sw_subj, verb_ls[index_min][0], no_sw_obj)\n",
    "                graph_tup_ls.append(tup)\n",
    "        \n",
    "        #clean_tup_ls = remove_dates(graph_tup_ls)\n",
    "    \n",
    "    dedup_tup_ls = remove_duplicates(graph_tup_ls, 2)\n",
    "    clean_tup_ls = remove_dates(dedup_tup_ls)\n",
    "    \n",
    "    return clean_tup_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def get_obj_properties(tup_ls):\n",
    "    \n",
    "    init_obj_tup_ls = []\n",
    "    \n",
    "    for tup in tup_ls:\n",
    "\n",
    "        try:\n",
    "            text, node_label_ls, url = query_google(tup[2], api_key, limit=1)\n",
    "            new_tup = (tup[0], tup[1], tup[2], text[0], node_label_ls[0], url[0])\n",
    "        except:\n",
    "            new_tup = (tup[0], tup[1], tup[2], [], [], [])\n",
    "        \n",
    "        init_obj_tup_ls.append(new_tup)\n",
    "        \n",
    "    return init_obj_tup_ls\n",
    "\n",
    "\n",
    "def add_layer(tup_ls):\n",
    "\n",
    "    svo_tup_ls = []\n",
    "    \n",
    "    for tup in tup_ls:\n",
    "        \n",
    "        if tup[3]:\n",
    "            svo_tup = create_svo_triples(tup[3])\n",
    "            svo_tup_ls.extend(svo_tup)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    return get_obj_properties(svo_tup_ls)\n",
    "        \n",
    "\n",
    "def subj_equals_obj(tup_ls):\n",
    "    \n",
    "    new_tup_ls = []\n",
    "    \n",
    "    for tup in tup_ls:\n",
    "        if tup[0] != tup[2]:\n",
    "            new_tup_ls.append((tup[0], tup[1], tup[2], tup[3], tup[4], tup[5]))\n",
    "            \n",
    "    return new_tup_ls\n",
    "\n",
    "\n",
    "def check_for_string_labels(tup_ls):\n",
    "    # This is for an edge case where the object does not get fully populated\n",
    "    # resulting in the node labels being assigned to string instead of list.\n",
    "    # This may not be strictly necessary and the lines using it are commnted out\n",
    "    # below.  Run this function if you come across this case.\n",
    "    \n",
    "    clean_tup_ls = []\n",
    "    \n",
    "    for el in tup_ls:\n",
    "        if isinstance(el[2], list):\n",
    "            clean_tup_ls.append(el)\n",
    "            \n",
    "    return clean_tup_ls\n",
    "\n",
    "\n",
    "def create_word_vectors(tup_ls):\n",
    "\n",
    "    new_tup_ls = []\n",
    "    \n",
    "    for tup in tup_ls:\n",
    "        if tup[3]:\n",
    "            doc = nlp(tup[3])\n",
    "            new_tup = (tup[0], tup[1], tup[2], tup[3], tup[4], tup[5], doc.vector)\n",
    "        else:\n",
    "            new_tup = (tup[0], tup[1], tup[2], tup[3], tup[4], tup[5], np.random.uniform(low=-1.0, high=1.0, size=(300,)))\n",
    "        new_tup_ls.append(new_tup)\n",
    "        \n",
    "    return new_tup_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's now run this step by step..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def dedup(tup_ls):\n",
    "    \n",
    "    visited = set()\n",
    "    output_ls = []\n",
    "    \n",
    "    for tup in tup_ls:\n",
    "        if not tup[0] in visited:\n",
    "            visited.add(tup[0])\n",
    "            output_ls.append((tup[0], tup[1], tup[2], tup[3], tup[4]))\n",
    "            \n",
    "    return output_ls\n",
    "\n",
    "\n",
    "def convert_vec_to_ls(tup_ls):\n",
    "    \n",
    "    vec_to_ls_tup = []\n",
    "    \n",
    "    for el in tup_ls:\n",
    "        vec_ls = [float(v) for v in el[4]]\n",
    "        tup = (el[0], el[1], el[2], el[3], vec_ls)\n",
    "        vec_to_ls_tup.append(tup)\n",
    "        \n",
    "    return vec_to_ls_tup\n",
    "\n",
    "\n",
    "def add_nodes(tup_ls):   \n",
    "\n",
    "    keys = ['name', 'description', 'node_labels', 'url', 'word_vec']\n",
    "    merge_nodes(graph.auto(), tup_ls, ('Node', 'name'), keys=keys)\n",
    "    print('Number of nodes in graph: ', graph.nodes.match('Node').count())\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def add_edges(edge_ls):\n",
    "    \n",
    "    edge_dc = {} \n",
    "    \n",
    "    # Group tuple by verb\n",
    "    # Result: {verb1: [(sub1, v1, obj1), (sub2, v2, obj2), ...],\n",
    "    #          verb2: [(sub3, v3, obj3), (sub4, v4, obj4), ...]}\n",
    "    \n",
    "    for tup in edge_ls: \n",
    "        if tup[1] in edge_dc: \n",
    "            edge_dc[tup[1]].append((tup[0], tup[1], tup[2])) \n",
    "        else: \n",
    "            edge_dc[tup[1]] = [(tup[0], tup[1], tup[2])] \n",
    "    \n",
    "    for edge_labels, tup_ls in tqdm(edge_dc.items()):   # k=edge labels, v = list of tuples\n",
    "        \n",
    "        tx = graph.begin()\n",
    "        \n",
    "        for el in tup_ls:\n",
    "            source_node = nodes_matcher.match(name=el[0]).first()\n",
    "            target_node = nodes_matcher.match(name=el[2]).first()\n",
    "            if not source_node:\n",
    "                source_node = Node('Node', name=el[0])\n",
    "                tx.create(source_node)\n",
    "            if not target_node:\n",
    "                try:\n",
    "                    target_node = Node('Node', name=el[2], node_labels=el[4], url=el[5], word_vec=el[6])\n",
    "                    tx.create(target_node)\n",
    "                except:\n",
    "                    continue\n",
    "            try:\n",
    "                rel = Relationship(source_node, edge_labels, target_node)\n",
    "            except:\n",
    "                continue\n",
    "            tx.create(rel)\n",
    "        tx.commit()\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def edge_tuple_creation(text):\n",
    "    \n",
    "    initial_tup_ls = create_svo_triples(text)\n",
    "    init_obj_tup_ls = get_obj_properties(initial_tup_ls)\n",
    "    new_layer_ls = add_layer(init_obj_tup_ls)\n",
    "    starter_edge_ls = init_obj_tup_ls + new_layer_ls\n",
    "    edge_ls = subj_equals_obj(starter_edge_ls)\n",
    "    edges_word_vec_ls = create_word_vectors(edge_ls)\n",
    "    \n",
    "    return edges_word_vec_ls\n",
    "\n",
    "\n",
    "def node_tuple_creation(edges_word_vec_ls):\n",
    "    \n",
    "    orig_node_tup_ls = [(edges_word_vec_ls[0][0], '', ['Subject'], '', np.random.uniform(low=-1.0, high=1.0, size=(300,)))]\n",
    "    obj_node_tup_ls = [(tup[2], tup[3], tup[4], tup[5], tup[6]) for tup in edges_word_vec_ls]\n",
    "    full_node_tup_ls = orig_node_tup_ls + obj_node_tup_ls\n",
    "    cleaned_node_tup_ls = check_for_string_labels(full_node_tup_ls)\n",
    "    #dedup_node_tup_ls = dedup(cleaned_node_tup_ls)\n",
    "    dedup_node_tup_ls = cleaned_node_tup_ls\n",
    "    node_tup_ls = convert_vec_to_ls(dedup_node_tup_ls)\n",
    "    \n",
    "    return node_tup_ls  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.6 s, sys: 521 ms, total: 32.1 s\n",
      "Wall time: 2min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('afghanistan transformation decade',\n",
       "  '',\n",
       "  ['Subject'],\n",
       "  '',\n",
       "  [0.04029161001196968,\n",
       "   0.14987617167610412,\n",
       "   0.45135238681125966,\n",
       "   -0.772807060369177,\n",
       "   -0.6634358449325086,\n",
       "   0.7902982591906424,\n",
       "   -0.17188821307821867,\n",
       "   -0.3770526335387543,\n",
       "   -0.8801027406242785,\n",
       "   0.2151907417638621,\n",
       "   0.4358778915220054,\n",
       "   -0.10052877702667762,\n",
       "   -0.4348362215248276,\n",
       "   -0.15257599621637996,\n",
       "   -0.15147239150379965,\n",
       "   -0.4958017182267216,\n",
       "   0.9434698395308456,\n",
       "   -0.803956712078802,\n",
       "   -0.36057640910808897,\n",
       "   -0.40754760234080134,\n",
       "   -0.604274914277062,\n",
       "   0.9864992361987632,\n",
       "   -0.5329207523977071,\n",
       "   -0.2209271866932958,\n",
       "   -0.45138125664402184,\n",
       "   -0.30178785943761643,\n",
       "   -0.3105846017593761,\n",
       "   -0.1681270452610435,\n",
       "   0.7413217599500996,\n",
       "   -0.3336173175415249,\n",
       "   -0.7248573895398753,\n",
       "   0.3949384731755432,\n",
       "   -0.7910149685157168,\n",
       "   -0.07089242969212672,\n",
       "   0.4262279497819148,\n",
       "   -0.294316608498959,\n",
       "   0.8408638364271483,\n",
       "   -0.08210457872997345,\n",
       "   -0.9277853620458407,\n",
       "   -0.8639475684539939,\n",
       "   -0.9760219360015641,\n",
       "   -0.8048800289066778,\n",
       "   0.17432472676726007,\n",
       "   -0.6042278770880498,\n",
       "   0.7294395037237205,\n",
       "   -0.9927095822604528,\n",
       "   -0.9112154327131083,\n",
       "   0.5491867271024189,\n",
       "   0.45787529746410405,\n",
       "   0.023519823547868635,\n",
       "   0.9709835716313915,\n",
       "   -0.010153192214917617,\n",
       "   0.2227345548758306,\n",
       "   0.6472252375741239,\n",
       "   -0.04353038168359369,\n",
       "   0.15167705954204447,\n",
       "   -0.9789146345139346,\n",
       "   0.9989309814456293,\n",
       "   0.8352577543015549,\n",
       "   0.6499971450462507,\n",
       "   -0.870456235899099,\n",
       "   -0.1967889251172661,\n",
       "   0.9648970447315395,\n",
       "   0.09899498702058884,\n",
       "   0.9790008958188376,\n",
       "   0.13817769125340074,\n",
       "   -0.15430651487885094,\n",
       "   0.8421341463467429,\n",
       "   -0.8427909634420452,\n",
       "   0.22783977825509294,\n",
       "   -0.7886555992145943,\n",
       "   0.43253800367417483,\n",
       "   -0.746961600721822,\n",
       "   0.009804590747016118,\n",
       "   -0.21984951605215786,\n",
       "   0.7423006129698484,\n",
       "   -0.9062841993482889,\n",
       "   -0.6415921682455243,\n",
       "   -0.3711602600314152,\n",
       "   -0.6526244174486966,\n",
       "   -0.8219022992168479,\n",
       "   0.9408869401733979,\n",
       "   -0.9367875323600356,\n",
       "   -0.3902036315605353,\n",
       "   0.09304088172530145,\n",
       "   -0.8034755869961154,\n",
       "   0.336484873408319,\n",
       "   0.031028726493723457,\n",
       "   -0.7898329228543164,\n",
       "   -0.3499008041505298,\n",
       "   -0.2623754036973658,\n",
       "   0.34541388270402584,\n",
       "   -0.46631306068426404,\n",
       "   -0.9216435504722198,\n",
       "   0.335785469700534,\n",
       "   0.2800209375764384,\n",
       "   0.988925194261544,\n",
       "   0.8677313191635194,\n",
       "   -0.6678090342873724,\n",
       "   0.512896323366687,\n",
       "   0.3812828392599079,\n",
       "   -0.2818563569652657,\n",
       "   -0.9355660018631515,\n",
       "   -0.41624305306900733,\n",
       "   -0.6123896124340646,\n",
       "   -0.5414372007840551,\n",
       "   -0.7618238653389493,\n",
       "   0.5596505969149745,\n",
       "   0.09967443884144278,\n",
       "   -0.31559878211665615,\n",
       "   0.41461775499955933,\n",
       "   -0.3064306762910307,\n",
       "   -0.13456260351621396,\n",
       "   -0.7928207605677313,\n",
       "   0.8902287969046581,\n",
       "   0.8258545951031133,\n",
       "   -0.2657823239286641,\n",
       "   -0.3387823358739315,\n",
       "   -0.19763278816590946,\n",
       "   -0.738820432557586,\n",
       "   -0.10604488194078021,\n",
       "   0.4777047318686778,\n",
       "   -0.9955470545703107,\n",
       "   0.8724034838909795,\n",
       "   0.739342620144823,\n",
       "   0.20296444088951815,\n",
       "   -0.01868453092413347,\n",
       "   0.240531762751524,\n",
       "   0.1813931606244188,\n",
       "   0.6359687621743362,\n",
       "   -0.1938547248374698,\n",
       "   -0.9670303297952203,\n",
       "   -0.5857352469953769,\n",
       "   -0.6704296506467071,\n",
       "   -0.42168807513454,\n",
       "   -0.5715703097759235,\n",
       "   -0.057369187282797274,\n",
       "   -0.3325531175674601,\n",
       "   -0.6768847119653509,\n",
       "   0.2274805680920946,\n",
       "   0.6254913843732777,\n",
       "   0.25272807889721194,\n",
       "   0.8264547185114655,\n",
       "   0.08998546227372595,\n",
       "   -0.12491480248310838,\n",
       "   -0.913506194781216,\n",
       "   0.37353222205909575,\n",
       "   0.537403092623935,\n",
       "   0.28513768000832407,\n",
       "   0.3477877939080267,\n",
       "   0.9800550106688184,\n",
       "   -0.9743255895100833,\n",
       "   0.2549967141809737,\n",
       "   -0.7043535093464053,\n",
       "   -0.08684917393374647,\n",
       "   0.8351138771647877,\n",
       "   0.4736048025655506,\n",
       "   -0.5097759042718737,\n",
       "   -0.7932126782665117,\n",
       "   0.8205134937474954,\n",
       "   -0.6095895211894515,\n",
       "   -0.4501279589307612,\n",
       "   0.2543396234992352,\n",
       "   0.3504209451533602,\n",
       "   0.6855927258763734,\n",
       "   0.5619440602675625,\n",
       "   0.7956094298071401,\n",
       "   -0.021660801887020575,\n",
       "   -0.2639779814491874,\n",
       "   -0.026366547859401734,\n",
       "   -0.33268808219522117,\n",
       "   0.2871490365823868,\n",
       "   -0.3495753499748362,\n",
       "   0.20569589694500845,\n",
       "   -0.8322726260220881,\n",
       "   -0.8173880454857874,\n",
       "   -0.6211349559242691,\n",
       "   0.10219119698425194,\n",
       "   0.966685621019256,\n",
       "   0.1113532973156397,\n",
       "   -0.19326582054141728,\n",
       "   0.7848874455532382,\n",
       "   -0.4691260405078983,\n",
       "   0.352578355356159,\n",
       "   -0.01971268951242977,\n",
       "   0.4698697525333291,\n",
       "   -0.6038125905466909,\n",
       "   0.38275529091288396,\n",
       "   0.394831459749047,\n",
       "   -0.8929245022569419,\n",
       "   0.45502246191934725,\n",
       "   0.07159867950473764,\n",
       "   0.2712136226336075,\n",
       "   0.6290979466447739,\n",
       "   -0.3738119765383552,\n",
       "   0.2135130043095823,\n",
       "   -0.2255964226893754,\n",
       "   0.9371314002280973,\n",
       "   -0.2732443154451918,\n",
       "   0.08979448913830335,\n",
       "   -0.2691309901038852,\n",
       "   0.7457395203500992,\n",
       "   -0.9607255769135945,\n",
       "   0.6506256571075433,\n",
       "   -0.5859010892999288,\n",
       "   -0.9467370563450968,\n",
       "   0.371155714782198,\n",
       "   -0.06437671824992508,\n",
       "   -0.9508772057419026,\n",
       "   0.6268960801961498,\n",
       "   -0.486039652600164,\n",
       "   0.7406362966858502,\n",
       "   -0.5825840349786084,\n",
       "   0.2047159354582515,\n",
       "   -0.9907491526676229,\n",
       "   0.19682495752289997,\n",
       "   0.013220654784952712,\n",
       "   -0.9491733612434241,\n",
       "   -0.22744554143298434,\n",
       "   0.6996725239504478,\n",
       "   0.19785835014118924,\n",
       "   -0.15116530170469789,\n",
       "   -0.6294869939443553,\n",
       "   0.15323932649997896,\n",
       "   0.5292333019146747,\n",
       "   0.20706423409320163,\n",
       "   -0.2810019778712649,\n",
       "   -0.5566969366701304,\n",
       "   -0.871992031159005,\n",
       "   0.07888261881697889,\n",
       "   0.24669146339467374,\n",
       "   0.0016821738410817133,\n",
       "   0.02749286369077364,\n",
       "   -0.694322460139913,\n",
       "   -0.35158270459269114,\n",
       "   -0.6853652287060126,\n",
       "   -0.9958629207371836,\n",
       "   -0.3500207007605478,\n",
       "   -0.015568652086574764,\n",
       "   0.7390812315291122,\n",
       "   0.957742649767541,\n",
       "   -0.23765739859763646,\n",
       "   0.9925705271690879,\n",
       "   0.5612604430596104,\n",
       "   0.3595141504635164,\n",
       "   -0.6991838101802783,\n",
       "   0.888426891097752,\n",
       "   -0.845463563290288,\n",
       "   0.8237515553681165,\n",
       "   -0.9403797432185597,\n",
       "   0.20771004057335807,\n",
       "   -0.506513012110162,\n",
       "   0.2932340580172961,\n",
       "   -0.6542799699545063,\n",
       "   -0.3113388997784514,\n",
       "   0.05706981349140117,\n",
       "   -0.6110896901482481,\n",
       "   0.7312587402300976,\n",
       "   -0.7106295086056387,\n",
       "   -0.8166952133940131,\n",
       "   -0.3079555681896493,\n",
       "   0.8617836391098612,\n",
       "   0.8933347768202269,\n",
       "   0.9170817412796806,\n",
       "   -0.9953857710484424,\n",
       "   0.36161993905644296,\n",
       "   -0.49117064398134835,\n",
       "   -0.8684009011182292,\n",
       "   -0.2597262330421086,\n",
       "   0.8693411644605324,\n",
       "   0.39146581272290737,\n",
       "   -0.7160933150809441,\n",
       "   0.9000994184903981,\n",
       "   -0.7268852332654543,\n",
       "   -0.6527227425677624,\n",
       "   -0.5979811038426124,\n",
       "   -0.04080695537008183,\n",
       "   0.3694919076505745,\n",
       "   0.27370881467485986,\n",
       "   -0.48308917852885136,\n",
       "   0.8516442268688198,\n",
       "   0.6337429116358924,\n",
       "   0.6811589338197388,\n",
       "   0.6644358946202344,\n",
       "   0.18597935952181666,\n",
       "   0.49813416121736087,\n",
       "   -0.02977970944446162,\n",
       "   0.4712709675858131,\n",
       "   -0.408220546871253,\n",
       "   -0.6660229900766408,\n",
       "   -0.8890311072223529,\n",
       "   0.7149294053399313,\n",
       "   0.7291344215925262,\n",
       "   0.14563614453896978,\n",
       "   -0.8889177023716643,\n",
       "   0.11869889185328408,\n",
       "   -0.6594727165927072,\n",
       "   0.5912623310982221,\n",
       "   -0.8051394490147443,\n",
       "   0.49530138275492996])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text = f\"\"\"\n",
    "1. The Afghanistan ‘Transformation Decade’ begins in 2015. With presidential \n",
    "elections in 2014, the withdrawal of international troops, and the closure of \n",
    "provincial reconstruction teams, Afghanistan continues its journey towards self\u0002reliance. The coming years will be marked by the full sovereignty of Afghanistan\n",
    "over its political, security and development processes. The international community \n",
    "and the United Nations will continue to support Afghanistan, as exemplified in the \n",
    "Tokyo Mutual Accountability Framework and the Chicago commitments on \n",
    "development and security. As Afghanistan enters its Transformation Decade, UNDP \n",
    "should also transition to meet emerging priorities and operational challenges, guided \n",
    "by the United Nations Development Assistance Framework and the new strategic \n",
    "plan, 2014-2017.\n",
    "2. Considerable development gains have been made since 2001, despite the \n",
    "continued insurgency in parts of the country — a conflict that led to close to 9,000 \n",
    "civilian casualties in 2013. Presidential elections were held in 2004, 2009 and 2014, \n",
    "the writ of the state has expanded across the country, and socio-economic \n",
    "development has led to growth in gross domestic product per capita from $186 in \n",
    "2002 to $688 in 2012. The Millennium Development Goals Report, 2012, suggests \n",
    "that Afghanistan should be able to achieve the Millennium Development Goals for \n",
    "education and health by its target year, 2020. Over 30 per cent of central \n",
    "government employees are women, and 28 per cent of the seats in the national \n",
    "parliament are reserved for women. With regard to proxy indicators used to \n",
    "determine multidimensional poverty levels, health and education show considerable \n",
    "improvement: infant mortality rates declined by more than 50 per cent between 2003 \n",
    "and 2012, and net enrolment in primary school rose from 54 per cent in 2003 to \n",
    "77 per cent in 2013. \n",
    "3. Progress has been uneven, however, across development sectors, between \n",
    "income groups, between men and women, and between rural and urban areas, and \n",
    "the country still faces conditions of fragility, a reduction of economic growth, and, \n",
    "currently, an acute cash crisis. Based on an analysis of development needs and \n",
    "guided by national development policies, as reflected in the United Nations \n",
    "Development Assistance Framework, the Tokyo Mutual Accountability Framework, \n",
    "the national priority programmes and the emerging ‘New Deal’ agenda, as well as \n",
    "the lessons learned reflected in the assessment of development results and the \n",
    "United Nations common country assessment, the United Nations family and partners \n",
    "have agreed to five outcomes to address fragility in its many dimensions and the \n",
    "root causes of conflict: (a) equitable economic development; (b) social services; \n",
    "(c) social equity and investment in human capital, (d) justice and the rule of law; \n",
    "and (e) accountable governance. Responding to the Kabul Conference request for a \n",
    "unified United Nations system, the United Nations country team has committed to \n",
    "increasing the effectiveness of the system. Furthermore, UNDP is supporting the \n",
    "implementation of the New Deal for Engagement in Fragile States principle s with \n",
    "the Ministry of Finance. The five New Deal peacebuilding and state building goals, \n",
    "leading to conflict transformation, will act as a foundation for progress towards the \n",
    "national priority programmes and will guide the Government towards inclusive, \n",
    "country-led and country-owned strategies. As part of the New Deal, and in line with \n",
    "the Monterrey, Rome, Paris, Accra and Busan aid effectiveness principles, UNDP is \n",
    "engaging in better aid management to gradually align development financing with national priorities, donor initiatives, country systems and accountability systems \n",
    "such as the Development Assistance Database, and is ensuring harmonized, sector\u0002wide approaches to the allocation of resources.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "initial_tup_ls = create_svo_triples(text, print_lists=False)\n",
    "\n",
    "initial_tup_ls[0:3]\n",
    "\n",
    "init_obj_tup_ls = get_obj_properties(initial_tup_ls)\n",
    "new_layer_ls = add_layer(init_obj_tup_ls)\n",
    "starter_edge_ls = init_obj_tup_ls + new_layer_ls\n",
    "edge_ls = subj_equals_obj(starter_edge_ls)\n",
    "#clean_edge_ls = check_for_string_labels(edge_ls)\n",
    "#clean_edge_ls[0:3]\n",
    "clean_edge_ls = edge_ls\n",
    "\n",
    "edge_ls[0:3]\n",
    "\n",
    "# edges_word_vec_ls = create_word_vectors(edge_ls)\n",
    "\n",
    "orig_node_tup_ls = [(edge_ls[0][0], '', ['Subject'], '', \n",
    "np.random.uniform(low=-1.0, high=1.0, size=(300,))\n",
    ")]\n",
    "# obj_node_tup_ls = [(tup[2], tup[3], tup[4], tup[5], tup[6]) for tup in edges_word_vec_ls]\n",
    "full_node_tup_ls = orig_node_tup_ls \n",
    "#  + obj_node_tup_ls\n",
    "dedup_node_tup_ls = dedup(full_node_tup_ls)\n",
    "\n",
    "len(full_node_tup_ls), len(dedup_node_tup_ls)\n",
    "node_tup_ls = convert_vec_to_ls(dedup_node_tup_ls)\n",
    "\n",
    "node_tup_ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Populate the graph db\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in graph:  83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]/var/folders/pq/bqmlvyrj2cx73wpm001ps2pr0000gn/T/ipykernel_85561/142667097.py:36: DeprecationWarning: The transaction.commit() method is deprecated, use graph.commit(transaction) instead\n",
      "  tx.commit()\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# If you are using a Sandbox instance, you will want to use the following (commented) line.  \n",
    "# If you are using a Docker container for your DB, use the uncommented line.\n",
    "# graph = Graph(\"bolt://some_ip_address:7687\", name=\"neo4j\", password=\"some_password\")\n",
    "\n",
    "graph = Graph(\"bolt://localhost:7687\", name=\"neo4j\", password=\"\")\n",
    "nodes_matcher = NodeMatcher(graph)\n",
    "\n",
    "add_nodes(node_tup_ls)\n",
    "add_edges(edges_word_vec_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29941c2a",
   "metadata": {},
   "source": [
    "### Updating nodes and edges in graph db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32af7110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# barack_text = wikipedia.summary('barack obama')\n",
    "# barack_edges_word_vec_ls = edge_tuple_creation(barack_text)\n",
    "# barack_node_tup_ls = node_tuple_creation(barack_edges_word_vec_ls)\n",
    "\n",
    "# michelle_text = wikipedia.summary('michelle obama')\n",
    "# michelle_edges_word_vec_ls = edge_tuple_creation(michelle_text)\n",
    "# michelle_node_tup_ls = node_tuple_creation(michelle_edges_word_vec_ls)\n",
    "\n",
    "\n",
    "# full_node_ls = barack_node_tup_ls + michelle_node_tup_ls\n",
    "# full_edge_ls = barack_edges_word_vec_ls + michelle_edges_word_vec_ls\n",
    "# full_dedup_node_tup_ls = dedup(full_node_ls)\n",
    "# print(len(full_node_ls), len(full_dedup_node_tup_ls))\n",
    "# add_nodes(full_dedup_node_tup_ls)\n",
    "# add_edges(full_edge_ls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
