{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai neo4j python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'is_union' from 'pydantic.typing' (/Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/pydantic/typing.cpython-39-darwin.so)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# from openai import OpenAI\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/__init__.py:8\u001b[0m\n\u001b[1;32m      <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/__init__.py?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_os\u001b[39;00m\n\u001b[1;32m      <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/__init__.py?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m override\n\u001b[0;32m----> <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/__init__.py?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m types\n\u001b[1;32m      <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/__init__.py?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_types\u001b[39;00m \u001b[39mimport\u001b[39;00m NoneType, Transport, ProxiesTypes\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/__init__.py?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m file_from_path\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/types/__init__.py:5\u001b[0m\n\u001b[1;32m      <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/types/__init__.py?line=0'>1</a>\u001b[0m \u001b[39m# File generated from our OpenAPI spec by Stainless.\u001b[39;00m\n\u001b[1;32m      <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/types/__init__.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m annotations\n\u001b[0;32m----> <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/types/__init__.py?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39medit\u001b[39;00m \u001b[39mimport\u001b[39;00m Edit \u001b[39mas\u001b[39;00m Edit\n\u001b[1;32m      <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/types/__init__.py?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m Image \u001b[39mas\u001b[39;00m Image\n\u001b[1;32m      <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/types/__init__.py?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m Model \u001b[39mas\u001b[39;00m Model\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/types/edit.py:6\u001b[0m\n\u001b[1;32m      <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/types/edit.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m List\n\u001b[1;32m      <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/types/edit.py?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m Literal\n\u001b[0;32m----> <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/types/edit.py?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_models\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseModel\n\u001b[1;32m      <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/types/edit.py?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcompletion_usage\u001b[39;00m \u001b[39mimport\u001b[39;00m CompletionUsage\n\u001b[1;32m      <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/types/edit.py?line=8'>9</a>\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mEdit\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mChoice\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_models.py:33\u001b[0m\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_models.py?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfields\u001b[39;00m \u001b[39mimport\u001b[39;00m FieldInfo\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_models.py?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_types\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_models.py?line=22'>23</a>\u001b[0m     Body,\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_models.py?line=23'>24</a>\u001b[0m     IncEx,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_models.py?line=30'>31</a>\u001b[0m     HttpxRequestFiles,\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_models.py?line=31'>32</a>\u001b[0m )\n\u001b[0;32m---> <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_models.py?line=32'>33</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_models.py?line=33'>34</a>\u001b[0m     is_list,\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_models.py?line=34'>35</a>\u001b[0m     is_given,\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_models.py?line=35'>36</a>\u001b[0m     is_mapping,\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_models.py?line=36'>37</a>\u001b[0m     parse_date,\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_models.py?line=37'>38</a>\u001b[0m     parse_datetime,\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_models.py?line=38'>39</a>\u001b[0m     strip_not_given,\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_models.py?line=39'>40</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_models.py?line=40'>41</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_compat\u001b[39;00m \u001b[39mimport\u001b[39;00m PYDANTIC_V2, ConfigDict\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_models.py?line=41'>42</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_compat\u001b[39;00m \u001b[39mimport\u001b[39;00m GenericModel \u001b[39mas\u001b[39;00m BaseGenericModel\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_utils/__init__.py:2\u001b[0m\n\u001b[1;32m      <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_utils/__init__.py?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_proxy\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyProxy \u001b[39mas\u001b[39;00m LazyProxy\n\u001b[0;32m----> <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_utils/__init__.py?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m flatten \u001b[39mas\u001b[39;00m flatten\n\u001b[1;32m      <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_utils/__init__.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m is_dict \u001b[39mas\u001b[39;00m is_dict\n\u001b[1;32m      <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_utils/__init__.py?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m is_list \u001b[39mas\u001b[39;00m is_list\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_utils/_utils.py:24\u001b[0m\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_utils/_utils.py?line=20'>21</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msniffio\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_utils/_utils.py?line=22'>23</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_types\u001b[39;00m \u001b[39mimport\u001b[39;00m Headers, NotGiven, FileTypes, NotGivenOr, HeadersLike\n\u001b[0;32m---> <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_utils/_utils.py?line=23'>24</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_compat\u001b[39;00m \u001b[39mimport\u001b[39;00m is_union \u001b[39mas\u001b[39;00m _is_union\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_utils/_utils.py?line=24'>25</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_compat\u001b[39;00m \u001b[39mimport\u001b[39;00m parse_date \u001b[39mas\u001b[39;00m parse_date\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_utils/_utils.py?line=25'>26</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_compat\u001b[39;00m \u001b[39mimport\u001b[39;00m parse_datetime \u001b[39mas\u001b[39;00m parse_datetime\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_compat.py:55\u001b[0m\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_compat.py?line=52'>53</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_compat.py?line=53'>54</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m get_args \u001b[39mas\u001b[39;00m get_args\n\u001b[0;32m---> <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_compat.py?line=54'>55</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m is_union \u001b[39mas\u001b[39;00m is_union\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_compat.py?line=55'>56</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m get_origin \u001b[39mas\u001b[39;00m get_origin\n\u001b[1;32m     <a href='file:///Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/openai/_compat.py?line=56'>57</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m is_typeddict \u001b[39mas\u001b[39;00m is_typeddict\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'is_union' from 'pydantic.typing' (/Users/davidoluyalegbenga/.pyenv/versions/3.9.6/lib/python3.9/site-packages/pydantic/typing.cpython-39-darwin.so)"
     ]
    }
   ],
   "source": [
    "# from openai import OpenAI\n",
    "import openai\n",
    "import json\n",
    "import urllib\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed  # Added missing imports\n",
    "import concurrent.futures\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')  # Ensure the punkt tokenizer is downloaded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dotenv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mload_dotenv\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_dotenv' is not defined"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/davidoluyalegbenga/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# from openai import OpenAI\n",
    "import openai\n",
    "import json\n",
    "import urllib\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed  # Added missing imports\n",
    "import concurrent.futures\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')  # Ensure the punkt tokenizer is downloaded\n",
    "\n",
    "\n",
    "# load_dotenv()\n",
    "# openai.api_key = os.getenv(\"OPENAI_KEY\")\n",
    "# # openai.api_version = os.getenv(\"api_version\")\n",
    "# openai.api_type = \"openai\"\n",
    "\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"api_key_azure\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_version = os.getenv(\"api_version\")\n",
    "openai_deployment = \"sdgi-gpt-4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = os.getenv(\"NEO4J_CONNECTION_URL\")\n",
    "username = os.getenv(\"NEO4J_USER\")\n",
    "password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_cypher_query(cypher_query):\n",
    "    driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "    \n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            session.run(cypher_query)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return 0\n",
    "        # print(f\"An error occurred while executing the Cypher query: {e}\")\n",
    "        # Handle the error here (e.g., log the error, raise an exception, etc.)\n",
    "    \n",
    "    finally:\n",
    "        driver.close()  # Close the Neo4j driver after execution (important)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract sentences from text content\n",
    "def extract_sentences(text):\n",
    "    return text.split('。')  # Split text by full stop (assuming full stop is '。' in Chinese)\n",
    "\n",
    "# def extract_sentences2(text):\n",
    "#     # Splitting by sentences\n",
    "#     sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "#     # Splitting by paragraphs (assuming double line breaks separate paragraphs)\n",
    "#     paragraphs = text.split('\\n\\n')  # or text.split('\\n\\n\\n') if triple line breaks\n",
    "#     return sentences, paragraphs\n",
    "\n",
    "# Function to extract text within quotes from a string\n",
    "def extract_quoted_text(text):\n",
    "    return re.findall(r'\"([^\"]*)\"', text)\n",
    "\n",
    "\n",
    "def custom_sentence_tokenizer(text, max_words=50):\n",
    "    words = text.split()\n",
    "    sentences = []\n",
    "    current_sentence = []\n",
    "\n",
    "    for word in words:\n",
    "        current_sentence.append(word)\n",
    "        if len(current_sentence) >= max_words and (word.endswith('.') or word.endswith('!') or word.endswith('?')):\n",
    "            sentences.append(' '.join(current_sentence))\n",
    "            current_sentence = []\n",
    "\n",
    "    if current_sentence:\n",
    "        sentences.append(' '.join(current_sentence))\n",
    "\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def extract_sentences2(text):\n",
    "    # Splitting by sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence(sentence):\n",
    "    try:\n",
    "        prompt = f\"\"\"\n",
    "        Given the  text content \"{sentence}\" generate Neo4j Cypher queries to create a knowledge graph based on the above. Only return the Cypher only. No explanations etc.\n",
    "        \"\"\"            \n",
    "        response = openai.chat.completions.create(\n",
    "                    model=openai_deployment,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt},\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        # Extract the category from the response\n",
    "        cypherCode = response.choices[0].message.content\n",
    "        print(cypherCode)\n",
    "        return cypherCode\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"OPEN AI An error occurred: {e}\")\n",
    "        return None  # Return None or handle the error as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files_concurrently(file_paths):\n",
    "    openai_responses = []\n",
    "    total_files = len(file_paths)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=5000) as executor_files:\n",
    "        futures_files = {executor_files.submit(process_text_file, file_path): file_path for file_path in file_paths}\n",
    "        with tqdm(total=total_files, desc='Processing Files') as pbar:\n",
    "            for future_file in tqdm(as_completed(futures_files), total=total_files, desc='Files'):\n",
    "                file_path = futures_files[future_file]\n",
    "                data = future_file.result()\n",
    "                if data:\n",
    "                    openai_responses.append(data)\n",
    "                pbar.update(1)  # Update progress bar for each file processed\n",
    "                pbar.set_description(f\"Processed {pbar.n}/{total_files} files\")\n",
    "    return openai_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_queries_concurrently(queries):\n",
    "    execute_cypher_query(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        file_content = file.read()\n",
    "        extracted_texts = file_content #extract_quoted_text(file_content)\n",
    "        if extracted_texts:\n",
    "            extracted_text = extracted_texts  # Considering the first quoted text\n",
    "            \n",
    "            sentences = custom_sentence_tokenizer(extracted_text)\n",
    "            print(f\"extracted_textssentences=== {len(sentences)}\")\n",
    "\n",
    "            with ThreadPoolExecutor(max_workers=3000) as executor_sentences:\n",
    "                futures_sentences = {executor_sentences.submit(process_sentence, sentence): sentence for sentence in sentences}\n",
    "                processed_cypher_queries = []\n",
    "                for future_sentence in tqdm(as_completed(futures_sentences), total=len(sentences), desc='Sentences'):\n",
    "                    query = future_sentence.result()\n",
    "                    if query:\n",
    "                        processed_cypher_queries.append(query)\n",
    "                        execute_queries_concurrently(query)\n",
    "                \n",
    "            return processed_cypher_queries\n",
    "        else:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing .txt files downloaded_text\n",
    "folder_path = 'Data/cleaned_text_manually'\n",
    "\n",
    "# Array to store OpenAI responses\n",
    "openai_responses = []\n",
    "\n",
    "# List to hold file paths\n",
    "file_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if filename.endswith('.txt')]\n",
    "\n",
    "process_files_concurrently(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain.graphs import Neo4jGraph\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=uri,\n",
    "    username=username,\n",
    "    password=password\n",
    ")\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    graph=graph,\n",
    "    cypher_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\"),\n",
    "    qa_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-16k\"),\n",
    "    verbose=True,\n",
    ")\n",
    "response = chain(\"what benefits does UNDP offer to Afghanistan\") #test the chain\n",
    "print(f\"Final answer: {response['result']}\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c263a8157c89e06b3874ec91de38deece4dd969ed3ec08b86dee9548e8b5ec9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('3.9.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
